# Phase 1 Week 1 - Database Setup & Crawler Architecture

## âœ… HoÃ n thÃ nh

### 1. MongoDB Schema Design
ðŸ“ **Files:** `schema/mongodb_schema.js`, `schema/README.md`

**Collections Ä‘Æ°á»£c thiáº¿t káº¿:**
- âœ… **POIs** - 800-1000 Ä‘á»‹a Ä‘iá»ƒm du lá»‹ch Vietnam
- âœ… **Users** - User profiles + MDPI learned preferences
- âœ… **Itineraries** - Generated tour plans vá»›i budget tracking
- âœ… **User_POI_Interactions** - Implicit feedback cho collaborative filtering
- âœ… **Algorithm_Models** - ML model metadata & versioning
- âœ… **System_Logs** - Performance monitoring vá»›i TTL auto-cleanup

**Key Features:**
- GeoJSON 2dsphere indexes cho geospatial queries
- Full-text search indexes (Vietnamese + English)
- Validation schemas cho data quality
- Budget optimization support (missing trong táº¥t cáº£ 3 papers!)
- Dietary restrictions & allergen tracking
- Dynamic staying time fields (NMF tá»« MDPI)
- Time-based user interest (MDPI Stage 1)

### 2. Setup Scripts
ðŸ“ **File:** `schema/setup_mongodb.py`

**Chá»©c nÄƒng:**
- âœ… Auto-create 6 collections vá»›i validation
- âœ… Create 15+ indexes cho performance
- âœ… Insert sample POI (Há»“ HoÃ n Kiáº¿m)
- âœ… Validate setup & test geospatial queries
- âœ… Support cáº£ local MongoDB vÃ  Atlas

**Usage:**
```bash
cd "Data Algorithm/schema"
pip install -r requirements.txt
python setup_mongodb.py
```

### 3. Data Crawler Architecture
ðŸ“ **File:** `crawler/crawler_architecture.py`

**Design Patterns:**
- âœ… Abstract `BaseCrawler` class (extensible)
- âœ… Async/await vá»›i aiohttp (high performance)
- âœ… Rate limiting per source (Google: 10 req/s, TripAdvisor: 5 req/s)
- âœ… Concurrent requests vá»›i semaphore (default 5)
- âœ… Automatic deduplication by name + location
- âœ… Standardized `POIData` model â†’ MongoDB format

**Implemented Crawlers:**
- âœ… **GooglePlacesCrawler** - Google Places API (primary source)
  - Text Search API (max 60 results per query)
  - Place Details API (full info)
  - Category mapping: Wanderlust â†’ Google types
  - Address parsing for Vietnam provinces
  
- â³ **TripAdvisorCrawler** - Placeholder (need API key)
- â³ **VietnamTravelScraper** - Placeholder (need BeautifulSoup implementation)

**Orchestrator:**
- âœ… `CrawlerOrchestrator` - Manages multiple crawlers
- âœ… Province-by-province crawling (9 target provinces)
- âœ… Auto-deduplication across sources
- âœ… JSON export for batch processing

---

## ðŸ“Š Target Data Collection (Week 1-2)

### Provinces Priority (800-1000 POIs total)

| Province | Target POIs | Priority | Reason |
|----------|-------------|----------|--------|
| HÃ  Ná»™i | 150-200 | ðŸ”´ High | Capital, rich culture |
| Há»“ ChÃ­ Minh | 150-200 | ðŸ”´ High | Largest city, diverse |
| ÄÃ  Náºµng | 80-100 | ðŸŸ¡ Medium | Central hub, beach |
| Quáº£ng Ninh | 80-100 | ðŸŸ¡ Medium | Háº¡ Long Bay UNESCO |
| LÃ o Cai | 80-100 | ðŸŸ¡ Medium | Sapa mountains |
| KhÃ¡nh HÃ²a | 80-100 | ðŸŸ¡ Medium | Nha Trang resort |
| KiÃªn Giang | 60-80 | ðŸŸ¢ Low | PhÃº Quá»‘c island |
| Thá»«a ThiÃªn Huáº¿ | 60-80 | ðŸŸ¢ Low | Imperial city |
| LÃ¢m Äá»“ng | 60-80 | ðŸŸ¢ Low | ÄÃ  Láº¡t highlands |

### Category Distribution

| Category | % | Target Count | Examples |
|----------|---|--------------|----------|
| Nature/Outdoor | 30% | 240-300 | Mountains, beaches, lakes, waterfalls |
| Culture/Historical | 25% | 200-250 | Temples, pagodas, museums, UNESCO sites |
| Food/Restaurant | 20% | 160-200 | Phá»Ÿ, bÃ¡nh mÃ¬, seafood, local specialties |
| Shopping | 10% | 80-100 | Markets, malls, craft villages |
| Entertainment | 10% | 80-100 | Theme parks, nightlife, shows |
| Adventure | 5% | 40-50 | Trekking, diving, rafting, caving |

---

## ðŸš€ Next Steps (Week 2)

### 1. Get API Keys (Day 1)
```bash
# Google Places API
# 1. Go to: https://console.cloud.google.com/
# 2. Create project "Wanderlust AI"
# 3. Enable "Places API" & "Maps JavaScript API"
# 4. Create credentials â†’ API Key
# 5. Restrict key to Places API only
# 6. Set quota: 10,000 requests/day (free tier)

# TripAdvisor API (Optional)
# 1. Go to: https://www.tripadvisor.com/developers
# 2. Register for API access
# 3. Note: Limited free tier, may need web scraping fallback
```

### 2. Run Initial Crawl (Day 2-3)
```bash
cd "Data Algorithm/crawler"
pip install -r requirements.txt

# Edit crawler_architecture.py:
# - Add your Google API key
# - Start with 2 provinces: ["HÃ  Ná»™i", "ÄÃ  Náºµng"]

python crawler_architecture.py

# Expected output: 300-400 POIs in crawled_pois.json
```

### 3. Data Quality Check (Day 4)
- Validate all POIs have coordinates
- Check description lengths (min 50 chars Vietnamese)
- Verify rating counts > 0
- Ensure categories are mapped correctly

### 4. Batch Insert to MongoDB (Day 5)
```python
# Create insert_pois.py script
import json
from pymongo import MongoClient

client = MongoClient("mongodb://localhost:27017/")
db = client["wanderlust_ai"]

with open("crawled_pois.json") as f:
    pois = json.load(f)

# Transform to MongoDB format
docs = [poi.to_mongodb_document() for poi in pois]

# Batch insert
result = db.pois.insert_many(docs)
print(f"Inserted {len(result.inserted_ids)} POIs")
```

### 5. Expand to All Provinces (Week 2)
- Add remaining 7 provinces
- Implement TripAdvisor crawler
- Add vietnam.travel scraper
- Target: 800-1000 POIs by end of Week 2

---

## ðŸ“ Project Structure

```
Data Algorithm/
â”œâ”€â”€ schema/
â”‚   â”œâ”€â”€ mongodb_schema.js       # âœ… Collection definitions
â”‚   â”œâ”€â”€ setup_mongodb.py        # âœ… Auto-setup script
â”‚   â”œâ”€â”€ requirements.txt        # âœ… pymongo, dnspython
â”‚   â””â”€â”€ README.md               # âœ… Detailed documentation
â”‚
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ crawler_architecture.py # âœ… Multi-source crawler
â”‚   â”œâ”€â”€ requirements.txt        # âœ… aiohttp, scrapy, beautifulsoup4
â”‚   â””â”€â”€ crawled_data/           # Output directory
â”‚       â”œâ”€â”€ crawled_pois.json
â”‚       â””â”€â”€ logs/
â”‚
â”œâ”€â”€ algorithm_comparison/
â”‚   â”œâ”€â”€ benchmark.py            # âœ… Performance testing
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ALGORITHM_COMPARISON_ANALYSIS.md  # âœ… 3-paper comparison
â”œâ”€â”€ DETAILED_IMPLEMENTATION_PLAN.md   # âœ… 16-week roadmap
â””â”€â”€ QUICK_START.md                    # âœ… Quick reference
```

---

## ðŸ’¡ Technical Decisions Made

### 1. MongoDB vs PostgreSQL?
**Choice: MongoDB**
- âœ… GeoJSON native support (2dsphere indexes)
- âœ… Flexible schema for varying POI data
- âœ… Horizontal scaling ready (sharding)
- âœ… JSON documents match API responses
- âœ… Easy to add new fields (e.g., new amenities)

### 2. Async vs Sync Crawler?
**Choice: Async (asyncio + aiohttp)**
- âœ… 5-10x faster for I/O-bound tasks
- âœ… Handle 1000s of API requests efficiently
- âœ… Rate limiting with semaphores
- âœ… Concurrent multi-source crawling

### 3. Real-time vs Batch Processing?
**Choice: Batch processing with periodic updates**
- âœ… POI data changes slowly (monthly updates sufficient)
- âœ… Easier error handling & retry logic
- âœ… Lower API costs (no real-time webhooks)
- âœ… Can process offline (PhoBERT, NLP)

### 4. Category System?
**Choice: Multi-category tags (array)**
- âœ… POIs often have multiple purposes (e.g., temple + historical + culture)
- âœ… Better for recommendation diversity
- âœ… Flexible filtering in queries
- âŒ Single category too restrictive

---

## ðŸ”§ Troubleshooting

### MongoDB Connection Issues
```bash
# Check if MongoDB is running
mongod --dbpath="D:/mongodb/data"

# Or use MongoDB Compass GUI
# Download: https://www.mongodb.com/products/compass
```

### Google Places API Quota Exceeded
```python
# Check quota usage in Google Cloud Console
# Free tier: 10,000 requests/month
# Each province search = ~60 results = 3 requests
# 9 provinces Ã— 6 categories Ã— 3 requests = 162 requests
# Still within free tier!

# If exceeded:
# - Reduce concurrent_requests in config
# - Add longer delays between provinces
# - Consider paid plan ($5/1000 requests)
```

### Deduplication Issues
```python
# If seeing too many duplicates:
# - Adjust coordinate rounding in _deduplicate_pois()
# - Currently: round(lat, 3) = ~100m precision
# - Increase to round(lat, 4) = ~10m precision for finer control
```

---

## ðŸ“ˆ Expected Metrics

### Week 1 End
- âœ… MongoDB schema complete with 6 collections
- âœ… 15+ indexes created
- âœ… Crawler architecture implemented
- â³ 0 POIs (API keys needed)

### Week 2 End
- â³ 800-1000 POIs collected
- â³ 9 provinces covered
- â³ 3 data sources integrated
- â³ 95%+ POIs with descriptions
- â³ 80%+ POIs with ratings

---

## ðŸŽ¯ Success Criteria

### Data Quality
- [ ] Every POI has valid coordinates
- [ ] 95%+ have Vietnamese descriptions (min 50 chars)
- [ ] 80%+ have ratings with count > 10
- [ ] All POIs have at least 1 category
- [ ] Entrance fees validated (0 for free POIs)

### Coverage
- [ ] All 9 target provinces represented
- [ ] Category distribution within 5% of target
- [ ] No duplicate POIs (same name + location)

### Performance
- [ ] Geospatial queries < 100ms
- [ ] Text search queries < 200ms
- [ ] Crawler processes 100 POIs/hour
- [ ] API rate limits not exceeded

---

## ðŸ“š References

- [MongoDB Schema Design Best Practices](https://www.mongodb.com/docs/manual/core/data-modeling-introduction/)
- [Google Places API Documentation](https://developers.google.com/maps/documentation/places/web-service/overview)
- [Python asyncio Tutorial](https://docs.python.org/3/library/asyncio.html)
- [MDPI Algorithm Paper](https://www.mdpi.com/2078-2489/12/10/402)

---

**Status:** âœ… Phase 1 Week 1 Complete  
**Next:** Week 2 - Data Collection & Quality Assurance  
**Updated:** 2026-01-06
